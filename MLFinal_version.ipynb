{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<H1><center>Credit Card Fraud Detection<center/></H1>\n",
    "<H3><center>Project By: Fares Makki | Mohamed Taha Sta | Jesser Hamdi<center/></H3>\n",
    "<H6><center><italic>CI-1 2023/2024</italic><center/></H6>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f09050882fe0066"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "from scipy.stats import norm\n",
    "import matplotlib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0a7f87de8e83632"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### A function to plot the confusion matrix."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "291d92615a2b6179"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None):\n",
    "    # Create a custom colormap using the colors you specified\n",
    "    cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"#928AEE\", \"#0F0B38\"])\n",
    "\n",
    "    plt.rcParams.update({'font.size': 19})\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontdict={'size': '16'})\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45, fontsize=12, color=\"#0F0B38\")\n",
    "    plt.yticks(tick_marks, classes, fontsize=12, color=\"#0F0B38\")\n",
    "    # rc('font', weight='bold')\n",
    "    fmt = '.1f'\n",
    "    thresh = cm.max()\n",
    "\n",
    "    # Calculate the percentages\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "\n",
    "    # Plot the text on the cells\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, \"\\n\" + format(cm_perc[i, j], '.2f') + \"%\",\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\")\n",
    "    plt.grid(False)\n",
    "    plt.ylabel('True label', fontdict={'size': '16'})\n",
    "    plt.xlabel('Predicted label', fontdict={'size': '16'})\n",
    "    plt.tight_layout()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c65bf2874506872"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Understanding the Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5331b8011a15b0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('creditcard.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e98cd1b680e0db2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a new feature 'Hour' from the 'Time' column\n",
    "data['Hour'] = data['Time'].apply(lambda x: int(np.floor(x / 3600)))\n",
    "\n",
    "# Visualize transactions by hour\n",
    "sns.set()\n",
    "palette = sns.color_palette([\"#0F0B38\", \"#928AEE\"])\n",
    "sns.set_palette(palette)\n",
    "sns.catplot(x='Hour', data=data, kind='count', hue='Class', height=5, aspect=3)\n",
    "plt.title('Transactions Per Hour')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab6b83d987c72daf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Set the aesthetic style of the plots\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Plot the distribution of transaction amount and time for fraud and normal transactions\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(12, 6))\n",
    "bins = 100\n",
    "\n",
    "# Plotting for Fraud transactions\n",
    "ax1.hist(data.Hour[data.Class == 1], bins=bins, color=palette[0], alpha=1)\n",
    "ax1.set_title('Fraud', fontsize=14)\n",
    "ax1.set_ylabel('Number of Transactions', fontsize=12)\n",
    "ax1.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Plotting for Normal transactions\n",
    "ax2.hist(data.Hour[data.Class == 0], bins=bins, color=palette[1], alpha=1)\n",
    "ax2.set_title('Normal', fontsize=14)\n",
    "ax2.set_xlabel('Time (in Hours)', fontsize=12)\n",
    "ax2.set_ylabel('Number of Transactions', fontsize=12)\n",
    "ax2.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Remove top and right spines\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "85c9bf6787478b0f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Understanding which normalisation method was used on the original dataset."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31c991e28288990d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "subset_of_features = ['V14', 'V12', 'V10', 'Class']\n",
    "sns.pairplot(data.sample(1000)[subset_of_features], hue='Class')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f58f564a3a9e38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Having examined the different features in the dataset we came to the conclusion that we were fortunate enough not to have extreme cases of outliers:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9158f5e9f37af4ef"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the distribution of some features for fraud transactions\n",
    "f, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "v14_fraud_dist = data['V14'].loc[data['Class'] == 1].values\n",
    "sns.distplot(v14_fraud_dist, ax=axes[0], fit=norm, color=palette[1])\n",
    "axes[0].set_title('V14 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "v12_fraud_dist = data['V12'].loc[data['Class'] == 1].values\n",
    "sns.distplot(v12_fraud_dist, ax=axes[1], fit=norm, color=palette[0])\n",
    "axes[1].set_title('V12 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "v10_fraud_dist = data['V10'].loc[data['Class'] == 1].values\n",
    "sns.distplot(v10_fraud_dist, ax=axes[2], fit=norm, color='#232FF4')\n",
    "axes[2].set_title('V10 Distribution \\n (Fraud Transactions)', fontsize=14)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4a0fbfbb7a124f4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the class distribution\n",
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "data['Class'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True, colors=palette[::-1])\n",
    "ax[0].set_title('Class Distribution')\n",
    "ax[0].set_ylabel('')\n",
    "sns.countplot(x='Class', data=data, ax=ax[1], palette=palette[::-1])\n",
    "ax[1].set_title('Distribution')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33a41836c1573c59"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pre-Processing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92a69b6ac64126ad"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove duplicates \n",
    "data.duplicated()\n",
    "data = data.drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69fdea97b3a96782"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Transform the data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data['Amount'] = scaler.fit_transform(data[['Amount']])\n",
    "data['Time'] = scaler.fit_transform(data[['Time']])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b70bb3d91f5cae91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Separate the data into normal and fraud\n",
    "legit = data[data.Class == 0]\n",
    "fraud = data[data.Class == 1]\n",
    "\n",
    "# Undersample the data to balance the classes\n",
    "legit_sample = legit.sample(500)\n",
    "new_data = pd.concat([legit_sample, fraud], axis=0)\n",
    "\n",
    "# Plot the semi equally distributed classes\n",
    "sns.countplot(x='Class', data=new_data, palette=palette)\n",
    "plt.title('Semi Equally Distributed Classes', fontsize=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5abe11daa64654c8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the correlation matrix for the new data\n",
    "plt.figure(figsize=(24, 20))\n",
    "sns.heatmap(new_data.corr(), cmap='coolwarm_r', annot_kws={'size': 20})\n",
    "plt.title('Sample Correlation Matrix', fontsize=14)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb5c7f73dba4a802"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can here by notice that the high_corr_features, which we are going to label as such, are ['V17', 'V14', 'V12', 'V10', 'V16', 'V3', 'V7', 'V11', 'V4', 'V2'].\n",
    "Which we are going to use later on for a second batch of models that we are going to run against the first batch which is going to be trained on all 30 variables."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b92aeba1bf51c56a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Split the data into features and labels\n",
    "x = new_data.drop(columns='Class', axis=1)  # features\n",
    "y = new_data['Class']  # label\n",
    "\n",
    "# Split the data into training and testing data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y, random_state=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8077839ee068be9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Models\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b3f09d83627525"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Take 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de727041e95cdf0d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the Logistic Regression model\n",
    "model1 = LogisticRegression()\n",
    "# Fit the model on the training data\n",
    "model1.fit(x_train, y_train)\n",
    "# Predict on the testing data\n",
    "y_pred1 = model1.predict(x_test)\n",
    "# Predict on the training data\n",
    "y_pred1_train = model1.predict(x_train)\n",
    "# Calculate the metrics\n",
    "accuracy1_train = accuracy_score(y_train, y_pred1_train)\n",
    "precision1_train = precision_score(y_train, y_pred1_train)\n",
    "recall1_train = recall_score(y_train, y_pred1_train)\n",
    "\n",
    "accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "precision1 = precision_score(y_test, y_pred1)\n",
    "recall1 = recall_score(y_test, y_pred1)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred1), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='Logistic Regression Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2754b9c88ad78e64"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the SVC model\n",
    "model2 = SVC(kernel='linear', random_state=42)\n",
    "# Fit the model on the training data\n",
    "model2.fit(x_train, y_train)\n",
    "# Predict on the testing data\n",
    "y_pred2 = model2.predict(x_test)\n",
    "# Predict on the training data\n",
    "y_pred2_train = model2.predict(x_train)\n",
    "# Calculate the metrics\n",
    "accuracy2_train = accuracy_score(y_train, y_pred2_train)\n",
    "precision2_train = precision_score(y_train, y_pred2_train)\n",
    "recall2_train = recall_score(y_train, y_pred2_train)\n",
    "\n",
    "accuracy2 = accuracy_score(y_test, y_pred2)\n",
    "precision2 = precision_score(y_test, y_pred2)\n",
    "recall2 = recall_score(y_test, y_pred2)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred2), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='SVC Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc24feba8e2ac77d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the Random Forest model\n",
    "model3 = RandomForestClassifier(n_estimators=3, random_state=0)\n",
    "# Fit the model on the training data\n",
    "model3.fit(x_train, y_train)\n",
    "# Predict on the testing data\n",
    "y_pred3 = model3.predict(x_test)\n",
    "# Predict on the training data\n",
    "y_pred3_train = model3.predict(x_train)\n",
    "# Calculate the metrics\n",
    "accuracy3_train = accuracy_score(y_train, y_pred3_train)\n",
    "precision3_train = precision_score(y_train, y_pred3_train)\n",
    "recall3_train = recall_score(y_train, y_pred3_train)\n",
    "\n",
    "accuracy3 = accuracy_score(y_test, y_pred3)\n",
    "precision3 = precision_score(y_test, y_pred3)\n",
    "recall3 = recall_score(y_test, y_pred3)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred3), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='Random Forest Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab25cbc5a91a990"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the KNN model\n",
    "model4 = KNeighborsClassifier(n_neighbors=3)\n",
    "# Fit the model on the training data\n",
    "model4.fit(x_train, y_train)\n",
    "# Predict on the testing data\n",
    "y_pred4 = model4.predict(x_test)\n",
    "# Predict on the training data\n",
    "y_pred4_train = model4.predict(x_train)\n",
    "# Calculate the metrics\n",
    "accuracy4_train = accuracy_score(y_train, y_pred4_train)\n",
    "precision4_train = precision_score(y_train, y_pred4_train)\n",
    "recall4_train = recall_score(y_train, y_pred4_train)\n",
    "\n",
    "accuracy4 = accuracy_score(y_test, y_pred4)\n",
    "precision4 = precision_score(y_test, y_pred4)\n",
    "recall4 = recall_score(y_test, y_pred4)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred4), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='KNN Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39d00ebcdbd3ddc6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Define the GaussianNB model\n",
    "model5 = GaussianNB()\n",
    "# Fit the model on the training data\n",
    "model5.fit(x_train, y_train)\n",
    "# Predict on the testing data\n",
    "y_pred5 = model5.predict(x_test)\n",
    "# Predict on the training data\n",
    "y_pred5_train = model5.predict(x_train)\n",
    "# Calculate the metrics\n",
    "accuracy5_train = accuracy_score(y_train, y_pred5_train)\n",
    "precision5_train = precision_score(y_train, y_pred5_train)\n",
    "recall5_train = recall_score(y_train, y_pred5_train)\n",
    "\n",
    "accuracy5 = accuracy_score(y_test, y_pred5)\n",
    "precision5 = precision_score(y_test, y_pred5)\n",
    "recall5 = recall_score(y_test, y_pred5)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test, y_pred5), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='GaussianNB Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "21cb90cc2b0dac4a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a list of results for each model\n",
    "results = [[accuracy1, precision1, recall1],\n",
    "           [accuracy2, precision2, recall2],\n",
    "           [accuracy3, precision3, recall3],\n",
    "           [accuracy4, precision4, recall4],\n",
    "           [accuracy5, precision5, recall5]]\n",
    "\n",
    "results_training = [[accuracy1_train, precision1_train, recall1_train],\n",
    "                    [accuracy2_train, precision2_train, recall2_train],\n",
    "                    [accuracy3_train, precision3_train, recall3_train],\n",
    "                    [accuracy4_train, precision4_train, recall4_train],\n",
    "                    [accuracy5_train, precision5_train, recall5_train]]\n",
    "\n",
    "results = [[round(x, 3) for x in row] for row in results]\n",
    "results_training = [[round(x, 3) for x in row] for row in results_training]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae6b88c383209993"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a list of metrics to evaluate\n",
    "metrics = [\"Accuracy (Training)\", \"Accuracy (Testing)\", \"Precision (Training)\", \"Precision (Testing)\",\n",
    "           \"Recall (Training)\", \"Recall (Testing)\"]\n",
    "\n",
    "# Concatenate the results and results_training lists\n",
    "results_combined = np.concatenate((results_training, results), axis=1)\n",
    "\n",
    "# Define a list of model names\n",
    "model_names = [\"Logistic Regression\", \"SVC\", \"Random Forest\", \"KNN\", \"GaussianNB\"]\n",
    "\n",
    "# Convert the results to a numpy array\n",
    "results_combined = np.array(results_combined)\n",
    "\n",
    "# Plot the table of results\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('off')\n",
    "\n",
    "# Create the table with the font properties and disable auto font size\n",
    "table = ax.table(cellText=results_combined, rowLabels=model_names, colLabels=metrics, cellLoc='center', loc='center',\n",
    "                 cellColours=plt.cm.RdYlGn(results_combined), colColours=[\"lightgray\"] * len(metrics),\n",
    "                 bbox=[0, 0, 1, 1])\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 2)\n",
    "plt.tight_layout()\n",
    "plt.title(\"Model Comparison\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7742a9c0383065b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Take 2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb17173082cd4340"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define a list of features that are highly correlated with the class\n",
    "high_corr_features = ['V17', 'V14', 'V12', 'V10', 'V16', 'V3', 'V7', 'V11', 'V4', 'V2']\n",
    "\n",
    "# Select only the high correlation features from the data\n",
    "x_high_corr = new_data[high_corr_features]\n",
    "y_high_corr = new_data['Class']\n",
    "\n",
    "# Split the data into training and testing data\n",
    "x_train_high_corr, x_test_high_corr, y_train_high_corr, y_test_high_corr = train_test_split(x_high_corr, y_high_corr,\n",
    "                                                                                            test_size=0.2,\n",
    "                                                                                            stratify=y_high_corr,\n",
    "                                                                                            random_state=2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a80f3b7586dfe421"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the KNN model with high correlation features\n",
    "model6 = KNeighborsClassifier(n_neighbors=3)\n",
    "# Fit the model on the training data\n",
    "model6.fit(x_train_high_corr, y_train_high_corr)\n",
    "# Predict on the testing data\n",
    "y_pred6 = model6.predict(x_test_high_corr)\n",
    "# Predict on the training data\n",
    "y_pred6_train = model6.predict(x_train_high_corr)\n",
    "# Calculate the metrics\n",
    "accuracy6_train = accuracy_score(y_train_high_corr, y_pred6_train)\n",
    "precision6_train = precision_score(y_train_high_corr, y_pred6_train)\n",
    "recall6_train = recall_score(y_train_high_corr, y_pred6_train)\n",
    "\n",
    "accuracy6 = accuracy_score(y_test_high_corr, y_pred6)\n",
    "precision6 = precision_score(y_test_high_corr, y_pred6)\n",
    "recall6 = recall_score(y_test_high_corr, y_pred6)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test_high_corr, y_pred6), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='KNN High Correlation Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7889dac4edb8c2c2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the SVC model\n",
    "model7 = SVC(kernel='linear', random_state=42)\n",
    "# Fit the model on the training data\n",
    "model7.fit(x_train_high_corr, y_train_high_corr)\n",
    "# Predict on the testing data\n",
    "y_pred7 = model7.predict(x_test_high_corr)\n",
    "# Predict on the training data\n",
    "y_pred7_train = model7.predict(x_train_high_corr)\n",
    "# Calculate the metrics\n",
    "accuracy7_train = accuracy_score(y_train_high_corr, y_pred7_train)\n",
    "precision7_train = precision_score(y_train_high_corr, y_pred7_train)\n",
    "recall7_train = recall_score(y_train_high_corr, y_pred7_train)\n",
    "\n",
    "accuracy7 = accuracy_score(y_test_high_corr, y_pred7)\n",
    "precision7 = precision_score(y_test_high_corr, y_pred7)\n",
    "recall7 = recall_score(y_test_high_corr, y_pred7)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test_high_corr, y_pred7), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='SVC High Correlation Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "84625258ecd9eed7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the Random Forest model\n",
    "model8 = RandomForestClassifier(n_estimators=3, random_state=0)\n",
    "# Fit the model on the training data\n",
    "model8.fit(x_train_high_corr, y_train_high_corr)\n",
    "# Predict on the testing data\n",
    "y_pred8 = model8.predict(x_test_high_corr)\n",
    "# Predict on the training data\n",
    "y_pred8_train = model8.predict(x_train_high_corr)\n",
    "# Calculate the metrics\n",
    "accuracy8_train = accuracy_score(y_train_high_corr, y_pred8_train)\n",
    "precision8_train = precision_score(y_train_high_corr, y_pred8_train)\n",
    "recall8_train = recall_score(y_train_high_corr, y_pred8_train)\n",
    "\n",
    "accuracy8 = accuracy_score(y_test_high_corr, y_pred8)\n",
    "precision8 = precision_score(y_test_high_corr, y_pred8)\n",
    "recall8 = recall_score(y_test_high_corr, y_pred8)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test_high_corr, y_pred8), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='Random Forest High Correlation Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a7e5b8bedc310c0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the Logistic Regression model\n",
    "model9 = LogisticRegression()\n",
    "# Fit the model on the training data\n",
    "model9.fit(x_train_high_corr, y_train_high_corr)\n",
    "# Predict on the testing data\n",
    "y_pred9 = model9.predict(x_test_high_corr)\n",
    "# Predict on the training data\n",
    "y_pred9_train = model9.predict(x_train_high_corr)\n",
    "# Calculate the metrics\n",
    "accuracy9_train = accuracy_score(y_train_high_corr, y_pred9_train)\n",
    "precision9_train = precision_score(y_train_high_corr, y_pred9_train)\n",
    "recall9_train = recall_score(y_train_high_corr, y_pred9_train)\n",
    "\n",
    "accuracy9 = accuracy_score(y_test_high_corr, y_pred9)\n",
    "precision9 = precision_score(y_test_high_corr, y_pred9)\n",
    "recall9 = recall_score(y_test_high_corr, y_pred9)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test_high_corr, y_pred9), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='Logistic Regression High Correlation Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e42d852ad2bcb53"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define the GaussianNB model\n",
    "model10 = GaussianNB()\n",
    "# Fit the model on the training data\n",
    "model10.fit(x_train_high_corr, y_train_high_corr)\n",
    "# Predict on the testing data\n",
    "y_pred10 = model10.predict(x_test_high_corr)\n",
    "# Predict on the training data\n",
    "y_pred10_train = model10.predict(x_train_high_corr)\n",
    "# Calculate the metrics\n",
    "accuracy10_train = accuracy_score(y_train_high_corr, y_pred10_train)\n",
    "precision10_train = precision_score(y_train_high_corr, y_pred10_train)\n",
    "recall10_train = recall_score(y_train_high_corr, y_pred10_train)\n",
    "\n",
    "accuracy10 = accuracy_score(y_test_high_corr, y_pred10)\n",
    "precision10 = precision_score(y_test_high_corr, y_pred10)\n",
    "recall10 = recall_score(y_test_high_corr, y_pred10)\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_matrix(y_test_high_corr, y_pred10), classes=['Non Fraud', 'Fraud'],\n",
    "                      title='GaussianNB High Correlation Confusion matrix')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57ca8e7d88ee6bdc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_high_corr = [[accuracy9, precision9, recall9],\n",
    "                     [accuracy7, precision7, recall7],\n",
    "                     [accuracy8, precision8, recall8],\n",
    "                     [accuracy6, precision6, recall6],\n",
    "                     [accuracy10, precision10, recall10]]\n",
    "\n",
    "results_training = [[accuracy9_train, precision9_train, recall9_train],\n",
    "                    [accuracy7_train, precision7_train, recall7_train],\n",
    "                    [accuracy8_train, precision8_train, recall8_train],\n",
    "                    [accuracy6_train, precision6_train, recall6_train],\n",
    "                    [accuracy10_train, precision10_train, recall10_train]]\n",
    "\n",
    "results_high_corr = [[round(x, 3) for x in row] for row in results_high_corr]\n",
    "results_training = [[round(x, 3) for x in row] for row in results_training]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88798f3ba479757f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Concatenate the results and results_training lists\n",
    "results_combined = np.concatenate((results_training, results_high_corr), axis=1)\n",
    "\n",
    "# Define a list of model names\n",
    "\n",
    "# Convert the results to a numpy array\n",
    "results_combined = np.array(results_combined)\n",
    "\n",
    "# Plot the table of results\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "ax.axis('off')  # Masquer les axes\n",
    "\n",
    "table = ax.table(cellText=results_combined, rowLabels=model_names, colLabels=metrics, cellLoc='center', loc='center',\n",
    "                 cellColours=plt.cm.RdYlGn(results_combined), colColours=[\"lightgray\"] * len(metrics),\n",
    "                 bbox=[0, 0, 1, 1])\n",
    "table.set_fontsize(12)\n",
    "table.scale(1, 2)\n",
    "plt.tight_layout()\n",
    "plt.title(\"High Correlation Model Comparison\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa541bd1c491a0b5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
